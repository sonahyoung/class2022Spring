{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "huggingface_gradio.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonahyoung/class2022Spring/blob/%EA%B8%B0%EB%A7%90%EB%B2%94%EC%9C%84/huggingface_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIc3wBXqPoAi"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface.load(\"huggingface/gpt2\").launch()  #이런 식으로 바로 되는 모델이 있고 안되는 게 있음"
      ],
      "metadata": {
        "id": "O_iU-KMVb3FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Image classification](https://huggingface.co/tasks/image-classification)\n",
        "\n",
        "\n",
        "사이트 들어가서 image classification 정의도 알아놓기, 시험문제에 이건 안다고 가정하고 낼거임"
      ],
      "metadata": {
        "id": "HiGiIwHHXyJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/google/vit-base-patch16-224 \\\n",
        "How to use\n",
        "\n",
        "에러메세지가 나오면 그거에 맞춰서 다시 해줘야함"
      ],
      "metadata": {
        "id": "N85f15SRXtON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "gJatB6PFZdse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'  #이미지가 있어야지 classification이 되는거니까 이미지를 불러와야함\n",
        "image = Image.open(requests.get(url, stream=True).raw)  #url을 불러와서 이미지를 오픈해와서, image가 숫자데이터로 저장이 되어있다. image 변수가 그림이라고 생각하면 됨.\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "#pretrained는 행렬임 (데이터로부터 잘 학습이 된 행렬) - Feature Extraction하는 모델, extracted된 정보를 가지고 classfication하는 모델 (변수 이름은 내 마음대로 정할 수 있지만 보고 추측하는 거임) \n",
        "#color image: 3층 정보 (R, G, B) / 흑백 이미지: 1층 정보 \n",
        "\n",
        "inputs = feature_extractor(images=image, return_tensors=\"pt\")  #숫자들 속에서 더 압축적으로 쓸 수 있는 정보로 뽑아내는 것\n",
        "#ex. 사람에 대한 정보를 뽑아낸다고 치면 무한대의 정보가 있지만, 그걸 feature 형태로 뽑아낸다고 하면, 눈썹이 어떻게 생겼고, 눈은 어떻게 생겼고, 남자고 여자고 이런거를 뽑아내는거임. object를 기술할 수 있는 핵심을 feature라고 생각하면 됨\n",
        "#그렇게 feature된 정보는 original raw 데이터보다는 개수가 더 작을거임\n",
        "outputs = model(**inputs)  #output은 classified된 정보가 나옴\n",
        "logits = outputs.logits\n",
        "# model predicts one of the 1000 ImageNet classes    #1000개의 class가 원래 들어가 있음. 그것중에 하나를 predict해내는 거임, 1000개의 숫자가 뽑아져나옴. 그거에 대한 확률이 다 나와서 다 더하면 1이 됨. \n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])  #그 중에서 확률이 제일 큰 걸 보여주라고 함 거임."
      ],
      "metadata": {
        "id": "ldZauC4yXfBT",
        "outputId": "cd510028-e055-42a5-f0c8-9474e89df5ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Egyptian cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이걸 이제 gradio화를 해야함. function 만들고 input, output 만들어야함.\n",
        "\n",
        "위의 코딩식은 script 형태임"
      ],
      "metadata": {
        "id": "9ZGOJqjLcpDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "CR7IwXS5Ybbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func (image):\n",
        "  feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "  model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "  inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "  outputs = model(**inputs)\n",
        "  logits = outputs.logits\n",
        "  # model predicts one of the 1000 ImageNet classes\n",
        "  predicted_class_idx = logits.argmax(-1).item()\n",
        "  predicted_class = model.config.id2label[predicted_class_idx]\n",
        "  return predicted_class  #이 함수는 이미지를 받아서 그것의 class를 text로 return한다"
      ],
      "metadata": {
        "id": "CA35L2ZPZveq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='image', outputs='text').launch()"
      ],
      "metadata": {
        "id": "bS2huLsOdOk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/tiger.jpg\"\n",
        "os.system(\"curl \" + url + \" > tiger.jpg\")\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/dog.jpg\"\n",
        "os.system(\"curl \" + url + \" > dog.jpg\")   #여기 구글 계정에 두 파일을 저장해라"
      ],
      "metadata": {
        "id": "v4FSg0gMbBLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='image', outputs='text', examples = ['tiger.jpg', 'dog.jpg']).launch()\n",
        "#examples 적을때는 list화해서 적어줘야함."
      ],
      "metadata": {
        "id": "h3N3dCkG2o3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Fill-Mask](https://huggingface.co/tasks/fill-mask)"
      ],
      "metadata": {
        "id": "Z8kY0va6YuS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/bert-base-uncased \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "IGD_q0SXfCF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "zR23S_FtfIkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "unmasker = pipeline('fill-mask', model='bert-base-uncased')  #bert-base-uncased라는 모델을 들고 와서 그걸 unmasker라고 하자는 거임\n",
        "unmasker(\"Hello I'm a [MASK] model.\")   #결과를 보면 list로 되어있는데, list의 item 이 5개가 들어있음. dictionary가 list로 묶여있음"
      ],
      "metadata": {
        "id": "spM_LYGees_k",
        "outputId": "51fa3ec6-10a5-45da-a779-170171bc40a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.10731077939271927,\n",
              "  'sequence': \"hello i'm a fashion model.\",\n",
              "  'token': 4827,\n",
              "  'token_str': 'fashion'},\n",
              " {'score': 0.0877445638179779,\n",
              "  'sequence': \"hello i'm a role model.\",\n",
              "  'token': 2535,\n",
              "  'token_str': 'role'},\n",
              " {'score': 0.05338413640856743,\n",
              "  'sequence': \"hello i'm a new model.\",\n",
              "  'token': 2047,\n",
              "  'token_str': 'new'},\n",
              " {'score': 0.046672213822603226,\n",
              "  'sequence': \"hello i'm a super model.\",\n",
              "  'token': 3565,\n",
              "  'token_str': 'super'},\n",
              " {'score': 0.027095887809991837,\n",
              "  'sequence': \"hello i'm a fine model.\",\n",
              "  'token': 2986,\n",
              "  'token_str': 'fine'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "KaobDkL0fRJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def func (text):\n",
        "  unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "  result = unmasker(text)\n",
        "  df = pd.DataFrame(result)   #아까 list로 되어있던 result를 dataframe화하면 그냥 dataframe이 되는거임\n",
        "  return df"
      ],
      "metadata": {
        "id": "3CKQl_oDfTsd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe').launch()"
      ],
      "metadata": {
        "id": "U6tjltrIiDRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\"Hello I'm a [MASK] model.\", \"It is raining outside. I feel [MASK].\"]"
      ],
      "metadata": {
        "id": "-OkQDYW2wju6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe', examples = examples).launch()"
      ],
      "metadata": {
        "id": "1aGFWiTUfl9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Token classification](https://huggingface.co/tasks/token-classification)\n",
        "\n",
        "natural language understanding task 분야임\n",
        "NER"
      ],
      "metadata": {
        "id": "0DDckwQ50cRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/dslim/bert-base-NER \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "mxv4tEUM0y_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "hUVn8h1304DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC).\n",
        "\n",
        "중요하다고 생각하는 entity만 뽑아내는거임\n",
        "-> 위치, 조직(단체), 사람 .. "
      ],
      "metadata": {
        "id": "9ksySb1Q50wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "#image classification과 비슷하게 두개의 pretrained를 불러옴 (두개의 AI 모델을 불러오는거임) - 단어 수준으로 쪼개주는 모델 하나, 각각의 단어들이 어떤 class인지 recognition해주는 모델\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer) \n",
        "example = \"My name is Wolfgang and I live in Berlin\"  \n",
        "\n",
        "ner_results = nlp(example)   #nlp가 모델임\n",
        "print(ner_results)   #결과를 보면, dataframe으로 해도 괜찮을거 같음 -> list로 되어있고, 내부적으로 2개의 dictionary로 되어있음"
      ],
      "metadata": {
        "id": "d9UOCPGJ0b1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "1CuE0WLi0x7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "def func (text):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "  model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "  nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "  result = nlp(text)\n",
        "  df = pd.DataFrame(result)\n",
        "  return df"
      ],
      "metadata": {
        "id": "jlx5iyV_0xV9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe').launch()"
      ],
      "metadata": {
        "id": "HumbYTd3kqam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\"My name is Wolfgang and I live in Berlin\", \"I will visit Seoul to see Chris\"]"
      ],
      "metadata": {
        "id": "upMTUXmc4fip"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe', examples = examples).launch()"
      ],
      "metadata": {
        "id": "Nes4r_Ek4fYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Sentence similarity](https://huggingface.co/tasks/sentence-similarity)\n",
        "\n",
        "두 주어진 문장이 있을때 얼마나 유사한가 보는거임\n",
        "\n",
        "모든 model은 input을 raw data를 바로 받아들일 수 없음, 중간단계가, converting 단계가 필요함 -> feature라고 하기도 하고 vector라고 하기도 하고 embedding이라고 하기도 함. (capture semantic information and calculate ~)"
      ],
      "metadata": {
        "id": "dE0umBRo7knv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "WJByl36a7lbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "lZvWkGmwAasZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sentences = [\"This is an example sentence\", \"it is one example writing\"]  #list\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "embeddings = model.encode(sentences)  #embeddings가 중요함.\n",
        "print(embeddings)\n",
        "#embeddings를 보면, [[     ], [      ]] 이런식으로 되어있음. 1번 list는 첫번째 text에 해당하고 2번 list는 두번째 text에 해당함."
      ],
      "metadata": {
        "id": "ahXHjR-x7nP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings) #list가 2개 들어있으니까 2라고 나올거임"
      ],
      "metadata": {
        "id": "5Ut-fQONmLZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[0])"
      ],
      "metadata": {
        "id": "5O97dn2DmTFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[1])   #384개의 숫자가 있구나를 이해하고 1번 list는 embedding for text1, 2번 list는 embedding for text2가 되는거임. 이 list안에 있는 숫자열이 feature vector인거임. 벡터는 숫자들이라고 했고, 데이터들이라고 했으니까 "
      ],
      "metadata": {
        "id": "z9tLd396Hthr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1,2]      [2,1]\n",
        "이런 벡터가 있다고 할때, 이거를 좌표평면에 찍어볼 수 있음. 이 두개가 얼마나 비슷한 지는 원점과 그 점을 이은 선 사이의 각도로 이야기할 수 있음. 각도가 0도이면 유사도가 제일 높고 각도가 90도이면 유사도가 제일 낮다고 생각하면 됨.\n",
        "cos(0) = 1 / cos(90) = 0이 됨.\n",
        "\n",
        "similarity between 2 vectors(embedding)은 벡터들의 각도값의 cos(세타)라고 하면 됨.\n",
        "-> 그걸 cos similarity라고 한다.\n",
        "\n",
        "벡터가 만약에 숫자가 3개면, 3개의 각도, 4개면 4개의 각도 ....\n",
        "차원이 아무리 늘어나도 두 벡터는 원점과 함께 삼각형을 만들게 되어있음. 각도가 항상 1개 나옴. \n",
        "\n",
        "-1<=cos(세타)=<1"
      ],
      "metadata": {
        "id": "aPKJbaD8mtA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_scores = util.pytorch_cos_sim(embeddings[0], embeddings[1])  #cos similarity를 계산해줌\n",
        "cosine_scores"
      ],
      "metadata": {
        "id": "Ne5AH2qbCZy_",
        "outputId": "204de280-5ac9-4b1c-e188-e98a482bcb82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5726]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "As33TUuTcJH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func (text1, text2):\n",
        "  from sentence_transformers import SentenceTransformer, util\n",
        "  model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "  embeddings = model.encode([text1, text2])  #text 1과 2를 list화\n",
        "  cosine_scores = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
        "  return cosine_scores"
      ],
      "metadata": {
        "id": "XqwC0HHicM71"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [[\"This is an example sentence\", \"it is one example writing\"], [\"A frog is hopping near the pond\", \"I love Korean Food\"]]"
      ],
      "metadata": {
        "id": "zZMVURDWcTNf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs=['text', 'text'], outputs='number', examples = examples).launch()"
      ],
      "metadata": {
        "id": "1pbOXexycTGR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}