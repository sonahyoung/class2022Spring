{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "huggingface_gradio.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonahyoung/class2022Spring/blob/%EA%B8%B0%EB%A7%90%EB%B2%94%EC%9C%84/huggingface_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIc3wBXqPoAi"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface.load(\"huggingface/gpt2\").launch()  #이런 식으로 바로 되는 모델이 있고 안되는 게 있음"
      ],
      "metadata": {
        "id": "O_iU-KMVb3FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Image classification](https://huggingface.co/tasks/image-classification)"
      ],
      "metadata": {
        "id": "HiGiIwHHXyJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/google/vit-base-patch16-224 \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "N85f15SRXtON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "gJatB6PFZdse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)  #image 변수가 그림이라고 생각하면 됨.\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "# model predicts one of the 1000 ImageNet classes\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "id": "ldZauC4yXfBT",
        "outputId": "9a7ef128-25e8-43d6-8961-7cd93b8678a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Egyptian cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이걸 이제 gradio화를 해야함. function 만들고 input, output 만들어야함."
      ],
      "metadata": {
        "id": "9ZGOJqjLcpDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "CR7IwXS5Ybbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func (image):\n",
        "  feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "  model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "  inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "  outputs = model(**inputs)\n",
        "  logits = outputs.logits\n",
        "  # model predicts one of the 1000 ImageNet classes\n",
        "  predicted_class_idx = logits.argmax(-1).item()\n",
        "  predicted_class = model.config.id2label[predicted_class_idx]\n",
        "  return predicted_class  #이 함수는 이미지를 받아서 그것의 class를 text로 return한다"
      ],
      "metadata": {
        "id": "CA35L2ZPZveq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='image', outputs='text').launch()"
      ],
      "metadata": {
        "id": "bS2huLsOdOk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/tiger.jpg\"\n",
        "os.system(\"curl \" + url + \" > tiger.jpg\")\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/dog.jpg\"\n",
        "os.system(\"curl \" + url + \" > dog.jpg\")"
      ],
      "metadata": {
        "id": "v4FSg0gMbBLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='image', outputs='text', examples = ['tiger.jpg', 'dog.jpg']).launch()\n",
        "#examples 적을때는 list화해서 적어줘야함."
      ],
      "metadata": {
        "id": "h3N3dCkG2o3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Fill-Mask](https://huggingface.co/tasks/fill-mask)"
      ],
      "metadata": {
        "id": "Z8kY0va6YuS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/bert-base-uncased \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "IGD_q0SXfCF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "zR23S_FtfIkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "unmasker(\"Hello I'm a [MASK] model.\")"
      ],
      "metadata": {
        "id": "spM_LYGees_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "KaobDkL0fRJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def func (text):\n",
        "  unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "  result = unmasker(text)\n",
        "  df = pd.DataFrame(result)\n",
        "  return df"
      ],
      "metadata": {
        "id": "3CKQl_oDfTsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\"Hello I'm a [MASK] model.\", \"It is raining outside. I feel [MASK].\"]"
      ],
      "metadata": {
        "id": "-OkQDYW2wju6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe', examples = examples).launch()"
      ],
      "metadata": {
        "id": "1aGFWiTUfl9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Token classification](https://huggingface.co/tasks/token-classification)"
      ],
      "metadata": {
        "id": "0DDckwQ50cRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/dslim/bert-base-NER \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "mxv4tEUM0y_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "hUVn8h1304DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."
      ],
      "metadata": {
        "id": "9ksySb1Q50wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "example = \"My name is Wolfgang and I live in Berlin\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)"
      ],
      "metadata": {
        "id": "d9UOCPGJ0b1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "1CuE0WLi0x7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "def func (text):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "  model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "  nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "  result = nlp(text)\n",
        "  df = pd.DataFrame(result)\n",
        "  return df"
      ],
      "metadata": {
        "id": "jlx5iyV_0xV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\"My name is Wolfgang and I live in Berlin\", \"I will visit Seoul to see Chris\"]"
      ],
      "metadata": {
        "id": "upMTUXmc4fip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe', examples = examples).launch()"
      ],
      "metadata": {
        "id": "Nes4r_Ek4fYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Sentence similarity](https://huggingface.co/tasks/sentence-similarity)"
      ],
      "metadata": {
        "id": "dE0umBRo7knv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "WJByl36a7lbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "lZvWkGmwAasZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sentences = [\"This is an example sentence\", \"it is one example writing\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "ahXHjR-x7nP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[1])"
      ],
      "metadata": {
        "id": "z9tLd396Hthr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_scores = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
        "cosine_scores"
      ],
      "metadata": {
        "id": "Ne5AH2qbCZy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "As33TUuTcJH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func (text1, text2):\n",
        "  from sentence_transformers import SentenceTransformer, util\n",
        "  model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "  embeddings = model.encode([text1, text2])\n",
        "  cosine_scores = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
        "  return cosine_scores"
      ],
      "metadata": {
        "id": "XqwC0HHicM71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [[\"This is an example sentence\", \"it is one example writing\"], [\"A frog is hopping near the pond\", \"I love Korean Food\"]]"
      ],
      "metadata": {
        "id": "zZMVURDWcTNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs=['text', 'text'], outputs='number', examples = examples).launch()"
      ],
      "metadata": {
        "id": "1pbOXexycTGR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}